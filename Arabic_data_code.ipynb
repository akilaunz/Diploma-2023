{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nuaeq3NnSU8_",
    "outputId": "928797ea-8fbc-4e2d-c880-5cae7f048caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./opt/anaconda3/lib/python3.9/site-packages (23.1.1)\n",
      "Requirement already satisfied: emot in ./opt/anaconda3/lib/python3.9/site-packages (3.1)\n",
      "Requirement already satisfied: emoji in ./opt/anaconda3/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: farasapy in ./opt/anaconda3/lib/python3.9/site-packages (0.0.14)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.9/site-packages (from farasapy) (2.28.1)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from farasapy) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->farasapy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->farasapy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->farasapy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->farasapy) (2022.9.24)\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/akzanuali/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/akzanuali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install --upgrade pip  \n",
    "!pip install emot\n",
    "!pip install emoji\n",
    "!pip install farasapy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import preprocessor as prepr\n",
    "import re\n",
    "import farasa\n",
    "import ast\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm.notebook import tqdm  \n",
    "from multiprocessing import Pool\n",
    "from farasa.segmenter import FarasaSegmenter\n",
    "from farasa.stemmer import FarasaStemmer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5DH4-gQFTbAN"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"arabic_data_train.csv\", index_col = None)[['text','sarcastic']]\n",
    "data_test = pd.read_csv(\"arabic_data_test.csv\", index_col = None)[['text','sarcastic']]\n",
    "\n",
    "data = pd.concat([data_train, data_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ARABIC_EMOJIS.txt') as f:\n",
    "    d = f.read()\n",
    "ARABIC_EMOJIS = ast.literal_eval(d)\n",
    "\n",
    "with open('ARABIC_EMOTICONS') as f:\n",
    "    d = f.read()\n",
    "ARABIC_EMOTICONS = ast.literal_eval(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('arabic')\n",
    "#               + ['«','»','،',':','؟','.',',','\"','*'])\n",
    "stemmer = ISRIStemmer()\n",
    "prepr.set_options(prepr.OPT.URL, prepr.OPT.MENTION, prepr.OPT.HASHTAG)\n",
    "\n",
    "def convert_emoji_to_text(text):\n",
    "    for emot in ARABIC_EMOJIS:\n",
    "        text = text.replace(emot, \"_\".join(ARABIC_EMOJIS[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text\n",
    "\n",
    "def convert_emoticon_to_text(text):\n",
    "    for emot in ARABIC_EMOTICONS:\n",
    "        text = text.replace(emot, \"_\".join(ARABIC_EMOTICONS[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text\n",
    "        \n",
    "def clean_text(text):\n",
    "    text = str(text) \n",
    "    text = convert_emoji_to_text(text)                                               #converting emojis to text\n",
    "    text = convert_emoticon_to_text(text)  \n",
    "    text = prepr.clean(text)                 \n",
    "    text = [stemmer.stem(token) for token in word_tokenize(text)]      #stemmatize+tokenization\n",
    "    text = [item for item in text if item not in stop_words]                  #stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b725f636249a44f1b1489838dd3c800a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = data.text\n",
    "cleaned_texts = []\n",
    "for item in tqdm(texts, total = len(texts)):\n",
    "    cleaned_texts.append(clean_text(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60eada60cbc44dda83f0e1ded211d940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_texts = []\n",
    "for text in tqdm(cleaned_texts, total = len(cleaned_texts)):\n",
    "    final_texts.append(' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('الل', 448),\n",
       " ('.', 435),\n",
       " ('ان', 369),\n",
       " (':', 321),\n",
       " ('!', 270),\n",
       " ('جمع', 226),\n",
       " ('فى', 204),\n",
       " ('مصر', 198),\n",
       " ('انا', 194),\n",
       " ('حمد', 194)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in cleaned_texts:\n",
    "    for word in text:\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_texts, data['sarcastic'].values, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics  \n",
    "def metrics_result(actual, predict):                       \n",
    "    print('Metrics:')\n",
    "    print ('Accuracy: {0: .3f}'.format(metrics.accuracy_score(actual, predict)) ) \n",
    "    print ('Precision: {0: .3f}'.format(metrics.precision_score(actual, predict,average='weighted')) ) \n",
    "    print ('Recall: {0: 0.3f}'.format(metrics.recall_score(actual, predict,average='weighted'))   )\n",
    "    print ('F1-score: {0:.3f}'.format(metrics.f1_score(actual, predict,average='weighted'))   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + Random Forest:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.801\n",
      "Precision:  0.776\n",
      "Recall:  0.801\n",
      "F1-score: 0.763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF Idf + Random Forest\n",
    "text_clf = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', RandomForestClassifier())\n",
    "                     ])\n",
    " \n",
    "text_clf.fit(X_train, y_train)\n",
    "print('TF Idf + Random Forest:')\n",
    "print()\n",
    "predicted = text_clf.predict(X_test)\n",
    "metrics_result(y_test, predicted)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + Logistic Regression:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.794\n",
      "Precision:  0.793\n",
      "Recall:  0.794\n",
      "F1-score: 0.726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_logreg = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('logreg', LogisticRegression())\n",
    "                     ])\n",
    " \n",
    "text_logreg.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + Logistic Regression:')\n",
    "print()\n",
    "predicted_l = text_logreg.predict(X_test)\n",
    "metrics_result(y_test,predicted_l)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + Naive Bayes:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.782\n",
      "Precision:  0.830\n",
      "Recall:  0.782\n",
      "F1-score: 0.691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_nb = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('nb', naive_bayes.MultinomialNB())\n",
    "                     ])\n",
    " \n",
    "text_nb.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + Naive Bayes:')\n",
    "print()\n",
    "predicted_nb = text_nb.predict(X_test)\n",
    "metrics_result(y_test,predicted_nb)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + SVM:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.805\n",
      "Precision:  0.784\n",
      "Recall:  0.805\n",
      "F1-score: 0.769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_svm = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('svm', svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'))\n",
    "                     ])\n",
    " \n",
    "text_svm.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + SVM:')\n",
    "print()\n",
    "predicted_svm = text_svm.predict(X_test)\n",
    "metrics_result(y_test,predicted_svm)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + Knn:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.801\n",
      "Precision:  0.787\n",
      "Recall:  0.801\n",
      "F1-score: 0.748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_knn = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('knn', KNeighborsClassifier(n_neighbors=7))\n",
    "                     ])\n",
    " \n",
    "text_knn.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + Knn:')\n",
    "print()\n",
    "predicted_knn = text_knn.predict(X_test)\n",
    "metrics_result(y_test,predicted_knn)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "TF Idf + Knn + Grid Search:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.797\n",
      "Precision:  0.780\n",
      "Recall:  0.797\n",
      "F1-score: 0.742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 10))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "text_knn_gr = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('knn_gr', GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1))\n",
    "                     ])\n",
    " \n",
    "text_knn_gr.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + Knn + Grid Search:')\n",
    "print()\n",
    "predicted_knn_gr = text_knn_gr.predict(X_test)\n",
    "metrics_result(y_test,predicted_knn_gr)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + Gradient Boosting:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.793\n",
      "Precision:  0.768\n",
      "Recall:  0.793\n",
      "F1-score: 0.735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_gb = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('gb', GradientBoostingClassifier())\n",
    "                     ])\n",
    " \n",
    "text_gb.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + Gradient Boosting:')\n",
    "print()\n",
    "predicted_gb = text_gb.predict(X_test)\n",
    "metrics_result(y_test,predicted_gb)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + SGD:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.799\n",
      "Precision:  0.784\n",
      "Recall:  0.799\n",
      "F1-score: 0.789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_sgd = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('sgd', SGDClassifier())\n",
    "                     ])\n",
    " \n",
    "text_sgd.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + SGD:')\n",
    "print()\n",
    "predicted_sgd = text_sgd.predict(X_test)\n",
    "metrics_result(y_test,predicted_sgd)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + Decision Tree:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.759\n",
      "Precision:  0.747\n",
      "Recall:  0.759\n",
      "F1-score: 0.752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_dt = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('dt', DecisionTreeClassifier())\n",
    "                     ])\n",
    " \n",
    "text_dt.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + Decision Tree:')\n",
    "print()\n",
    "predicted_dt = text_dt.predict(X_test)\n",
    "metrics_result(y_test,predicted_dt)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Idf + Ada Boost:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.787\n",
      "Precision:  0.752\n",
      "Recall:  0.787\n",
      "F1-score: 0.750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_ab = Pipeline([\n",
    "                     ('tfidf', TfidfVectorizer()),\n",
    "                     ('ab', AdaBoostClassifier())\n",
    "                     ])\n",
    " \n",
    "text_ab.fit(X_train, y_train)\n",
    "\n",
    "print('TF Idf + Ada Boost:')\n",
    "print()\n",
    "predicted_ab = text_ab.predict(X_test)\n",
    "metrics_result(y_test,predicted_ab)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [sentence.split() for sentence in X_train]\n",
    "w2v_model = Word2Vec(sentences, window=5, min_count=5, workers=4)\n",
    "\n",
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)\n",
    "\n",
    "X_train_w2v = np.array([vectorize(sentence) for sentence in X_train])\n",
    "X_test_w2v = np.array([vectorize(sentence) for sentence in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec + Random Forest:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.778\n",
      "Precision:  0.720\n",
      "Recall:  0.778\n",
      "F1-score: 0.697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    " \n",
    "clf.fit(X_train_w2v, y_train)\n",
    "print('Word2Vec + Random Forest:')\n",
    "print()\n",
    "predicted = clf.predict(X_test_w2v)\n",
    "metrics_result(y_test, predicted)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec + LogisticRegression:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.778\n",
      "Precision:  0.605\n",
      "Recall:  0.778\n",
      "F1-score: 0.681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    " \n",
    "lgr.fit(X_train_w2v, y_train)\n",
    "print('Word2Vec + LogisticRegression:')\n",
    "print()\n",
    "predicted = lgr.predict(X_test_w2v)\n",
    "metrics_result(y_test, predicted)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec + SVM:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.778\n",
      "Precision:  0.605\n",
      "Recall:  0.778\n",
      "F1-score: 0.681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svmm = svm.SVC(C=5.0, kernel='linear', degree=5, gamma='auto')\n",
    " \n",
    "svmm.fit(X_train_w2v, y_train)\n",
    "print('Word2Vec + SVM:')\n",
    "print()\n",
    "predicted = svmm.predict(X_test_w2v)\n",
    "metrics_result(y_test, predicted)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec + SGD:\n",
      "\n",
      "Metrics:\n",
      "Accuracy:  0.778\n",
      "Precision:  0.605\n",
      "Recall:  0.778\n",
      "F1-score: 0.681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    " \n",
    "sgd.fit(X_train_w2v, y_train)\n",
    "print('Word2Vec + SGD:')\n",
    "print()\n",
    "predicted = sgd.predict(X_test_w2v)\n",
    "metrics_result(y_test, predicted)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
